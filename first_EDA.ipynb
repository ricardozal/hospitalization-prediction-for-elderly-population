{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Part\n",
    "### Data and Features\n",
    "The dataset H_MHAS_c2.sas7bdat has 26839 rows and 5241 features.\n",
    "\n",
    "SOME IMPORTANT INSIGHTS\n",
    "-   The first character of the majority of variables indicates whether the variable refers to the reference person (“r”), spouse (“s”), or household (“h”).\n",
    "-   The second character indicates the wave to which the variable pertains: “1”, “2”, “3”, “4”, “5”, or “A”. The “A” indicates “all,”\n",
    "\n",
    "All features are divided into the following sections.\n",
    "\n",
    "- SECTION A: DEMOGRAPHICS, IDENTIFIERS, AND WEIGHTS\n",
    "- SECTION B: HEALTH\n",
    "- SECTION C: HEALTH CARE UTILIZATION AND INSURANCE\n",
    "- SECTION D: COGNITION\n",
    "- SECTION E: FINANCIAL AND HOUSING WEALTH\n",
    "- SECTION F: INCOME\n",
    "- SECTION G: FAMILY STRUCTURE\n",
    "- SECTION H: EMPLOYMENT HISTORY\n",
    "- SECTION I: RETIREMENT\n",
    "- SECTION J: PENSION\n",
    "- SECTION K: PHYSICAL MEASURES\n",
    "- SECTION L: ASSISTANCE AND CAREGIVING\n",
    "- SECTION M: STRESS\n",
    "- SECTION O: END OF LIFE PLANNING\n",
    "- SECTION Q: PSYCHOSOCIAL\n",
    "\n",
    "We have decided to analyze the features by sections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[H_MHAS_c2.sas7bdat] column count mismatch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset has 26839 rows and 5241 features\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.section_dict import (\n",
    "    section_A, # A: DEMOGRAPHICS, IDENTIFIERS, AND WEIGHTS\n",
    "    section_B, # B: HEALTH\n",
    "    section_C, # C: HEALTH CARE UTILIZATION AND INSURANCE\n",
    "    section_D, # D: COGNITION\n",
    "    section_E, # E: FINANCIAL AND HOUSING WEALTH\n",
    "    section_F, # F: INCOME\n",
    "    section_G, # G: FAMILY STRUCTURE\n",
    "    section_H, # H: EMPLOYMENT HISTORY\n",
    "    section_I, # I: RETIREMENT\n",
    "    section_J, # J: PENSION\n",
    "    section_K, # K: PHYSICAL MEASURES\n",
    "    section_L, # L: ASSISTANCE AND CAREGIVING\n",
    "    section_M, # M: STRESS\n",
    "    section_O, # O: END OF LIFE PLANNING\n",
    "    section_Q  # Q: PSYCHOSOCIAL\n",
    ")\n",
    "# read the dataset from the file (470 MB)\n",
    "with SAS7BDAT('./dataset/H_MHAS_c2.sas7bdat') as file:\n",
    "    df = file.to_data_frame()\n",
    "\n",
    "print('the dataset has '+ str(df.shape[0]) + ' rows and ' + str(df.shape[1]) + ' features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we check if all the columns extracted from the guide document are in the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document shows 5237 features and the data has 5241 features.\n",
      "\n",
      "The 4 variables that are not in the document:\n",
      "['r2relgwk', 's2relgwk', 'r5riccaredpmm', 's1rpfcaredpm']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the appended values\n",
    "Total_sections = []\n",
    "\n",
    "# Iterate over each dictionary and its values\n",
    "for section_dict in ( section_A, section_B, section_C, section_D, section_E, section_F, section_G, section_H, section_I, section_J, section_K, section_L, section_M, section_O, section_Q):\n",
    "    for values_list in section_dict.values():\n",
    "        # Extend the appended_values list with the values from the current list\n",
    "        Total_sections.extend(values_list)\n",
    "\n",
    "\n",
    "# all variables in the dataset...\n",
    "all_variables = df.columns.tolist()\n",
    "\n",
    "# Print the appended values\n",
    "print('The document shows ' + str(len(Total_sections)) +  ' features and the data has ' + str(len(all_variables)) + ' features.\\n')\n",
    "\n",
    "# Searching for variable names that are not in the document...\n",
    "variables_not_in_list = [variable for variable in all_variables if variable not in Total_sections]\n",
    "\n",
    "print('The ' + str(len(variables_not_in_list)) + ' variables that are not in the document:')\n",
    "print(variables_not_in_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they are not in the PDF guide document, we can delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26839, 5237)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=variables_not_in_list,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach we can take at this stage is to look for null values; since the data were produced in an interview, many columns contain a high percentage of null data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 columns with higher missing percentage:\n",
      "            Total  Missing Percentage\n",
      "s5penage    26835               100.0\n",
      "r3bpref     26839               100.0\n",
      "s3wghtsft   26827               100.0\n",
      "s3gripothr  26836               100.0\n",
      "s2penage    26827               100.0\n",
      "r5penage    26826               100.0\n",
      "s5dmonth    26839               100.0\n",
      "s5dyear     26839               100.0\n",
      "r3bpsft     26839               100.0\n",
      "s3bpsft     26839               100.0\n",
      "s3bpref     26839               100.0\n",
      "r3wghtref   26837               100.0\n",
      "s3walksft   26832               100.0\n",
      "s3walktryu  26832               100.0\n",
      "s3walkref   26832               100.0\n",
      "s3walkothr  26832               100.0\n",
      "r3gripsft   26833               100.0\n",
      "s3gripsft   26836               100.0\n",
      "r3gripref   26833               100.0\n",
      "s3gripref   26836               100.0\n",
      "s3wghttryu  26827               100.0\n",
      "r3gripothr  26833               100.0\n",
      "s3wghtref   26839               100.0\n",
      "s3hipref    26824                99.9\n",
      "r3wsttryu   26806                99.9\n",
      "r1penage    26813                99.9\n",
      "r3walkothr  26818                99.9\n",
      "r3sthtsft   26801                99.9\n",
      "s3sthtsft   26822                99.9\n",
      "r3sthttryu  26801                99.9\n",
      "r3walkref   26818                99.9\n",
      "s3sthttryu  26822                99.9\n",
      "r3wstref    26806                99.9\n",
      "r3sthtref   26801                99.9\n",
      "r3hipsft    26807                99.9\n",
      "r3walktryu  26818                99.9\n",
      "s3sthtref   26822                99.9\n",
      "s3wstref    26824                99.9\n",
      "r3walksft   26818                99.9\n",
      "r2penage    26822                99.9\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of missing data for each column\n",
    "total_values = df.isnull().sum()\n",
    "\n",
    "missing_percentage = round((total_values / len(df)) * 100,1)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "missing_data_df = pd.DataFrame({\n",
    "    'Total': total_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by missing percentage in descending order\n",
    "missing_data_df = missing_data_df.sort_values(by='Missing Percentage', ascending=False)\n",
    "\n",
    "# Display the top 20 columns with higher missing percentage\n",
    "top_missing_columns = missing_data_df.head(40)\n",
    "print(\"Top 20 columns with higher missing percentage:\")\n",
    "print(top_missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
